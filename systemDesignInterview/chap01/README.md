# chap01. 사용자 수에 따른 규모 확장성
## 단일 서버
모든 컴포넌트가 단 한 대의 서버에서 실행되는 간단한 시스템을 설계해보자.
엡, 웹, 데이터베이스, 캐시 등이 전부 서버 한 대에서 실행된다.  
사용자 요청 처리 흐름은 다음과 같다.
1. 사용자는 도메인 이름을 이용해 웹 사이트에 접속한다. 이 접속을 위해서 도메인 이름을 DNS에 질의하여 IP주소로 변환하는 과정이 필요하다. 
2. DNS조회 결과로 IP 주소가 반환된다.
3. 해당 IP주소로 HTTP 요청이 전달된다.
4. 요청을 받은 웹 서버는 HTML 페이지나 JSON 형태의 응답을 반환한다.  

이제 실제 요청이 어디로부터 오는지 살펴보자. 
* 웹 어플리케이션: 비즈니스 로직, 데이터 저장 등을 처리하기 위해서 서버용 언어를 사용, 프레젠테이션용으로는 클라이언트 구현용 언어를 사용한다.
* 모바일 앱: 모바일 앱과 웹 서버 간의 통신을 위해서는 HTTP 프로토콜을 이용한다. 

## 데이터 베이스
사용자가 늘면 서버 하나로 충분하지 않아 여러대의 서버가 필요하다. 하나는 웹/모바일 트래픽 처리 용도고, 하나는 DB용이다.  
### 어떤 DB를 사용할 것인가?
1. 관계형 DB (RDBMS)
MySQL, Oracle, PorsgresSQL 등이 있다. 관계형 DB는 자료를 테이블과 열, 칼럼으로 표현한다. 
SQL을 사용하면 여러 테이블에 있는 데이터를 그 관계에 따라 조인(join)하여 합칠 수 있다.
2. 비 관계형 DB (NoSQL)
CouchDB, Cassandra, HBase, DynamoDB등이 있다. NoSQL은 다시 네 부류로 나눌 수 있는데, 키 값-저장소, 그래프 저장소, 칼럼 저장소, 그리고 문서 자장소가 있다. 
일반적으로 조인 연산은 지원하지 않는다.  

대부분은 RDBMS를 많이 사용할 테지만, 다음과 같은 경우는 NoSQL이 바랍직한 선택일 수 있다.
* 아주 낮은 응답 지연시간 (latency)이 요구됨
* 다루는 데이터가 비정형이라 관계형 데이터가 아님
* 데이터를 직렬화하거나 역직렬화 할 수 있기만 하면 됨
* 아주 많은 양의 데이터를 저장할 필요가 있음

## 수직적 규모 확장 vs 수평적 규모 확장
* 수직적 규모 학장 또는 스케일 업(scale up)은 서버에 고사양 자원을 추가하는 행위를 말한다.
* 수평작 규모 확장 또는 스케일 아웃(scale out)은 더 많은 서버를 추가하여 성능을 개선하는 행위를 말한다.  

서버로 유입되는 트래픽의 양이 적을 때는 수직적 확장이 좋은 선택이며, 단순하다. 하지만 몇 가지 단점이 존재한다.
* 한 대의 서버에 CPU나 메모리를 무한대로 증설할 방법은 없으므로 한계가 있다.
* 장애에 대한 자동복구 방안이나 다중화 방안을 제기하지 않는다. 서버에 장애가 발생하면 웹사이트/엡은 완전히 중단된다.   

이러한 이유 때문에 대규모 애플리케이션 에서는 수평적 규모 확장이 조금 더 적절하다.  

### 로드밸런서
로드밸런서는 부하 분산 집합에 속한 우베 서버들에게 트래픽 부하를 고르게 분산하는 역할을 한다.  
사용자는 로드밸런서의 공개 IP주소로 접속한다. 웹 서버는 클라이언트의 접속을 직접 처리하지 않는다. 
보안을 위해 서버 간 통신에는 사설 IP주소가 이용된다.  
부하 분산 집합에 웹 서버를 추가하면 장애를 자동 복구하지 못하는 문제는 해소 되며, 웹 계층의 가용성은 향상된다.
* 서버 1이 다운되면 모든 트래픽은 서버 2로 전송된다. 즉, 웹 사이트 전체가 다운되는 일이 방지된다. 부하를 나누기 위해 새로운 서버를 추가할 수 맀다.
* 웹사이트로 유입되는 트래픽이 증가하면, 보유하고 있는 서버로 트래픽을 감당할 수 없는 시점이 오는데, 웹 서버 계층에 더 많은 서버를 추가하면 된다. 로드밸런스가 자동적으로 트래픽을 분산할 것이다.  

### 데이터베이스 다중화
보통 서버 사이에 주 서버와 부 서버 관계를 설정하고, 데이터 원본은 주 서버에, 사본은 부 서버에 저장하는 방식이다.  
쓰기 연산은 주 서버에서만 지원한다. 부 서버는 주 서버에서 그 사본을 전달 받으며, 읽기 연산만을 지원한다.  
대부분의 애플리케이션은 읽기 연산의 비중이 쓰기 연산보다 훨씬 높다. 그러므로 부 DB의 수가 주 DB의 수보다 많다. DB 다중화는 아래와 같은 장점을 가지고 있다.
* 더 나은 성능: 병렬로 처리될 수 있는 질의(query)의 수가 늘어나므로, 성능이 좋아진다. 
* 안정성: 데이터를 지역적으로 떨어진 여러 장소에 다중화 시켜 놓을 수 있으므로, DB서버 가운데 일부가 파괴되어도 데이터가 보존될 것이다. 
* 가용성: 데이터를 여러 지역에 복제해 둠으로써 하나의 DB서버에 장애가 발생하더라도 다른 서버에 있는 데이터를 가져와 계속 서비스 할 수 있다.  

DB서버 가운데 하나가 다운되면 무슨 일이 벌어질까?
* 부 서버가 한 대 뿐인데 다운된 경우라면 읽기 연산은 한시적으로 모두 주 DB로 전달될 것이다. 즉시 새로운 부 DB 가 장애 서버를 대체할 것이다. 
* 주 DB가 다운되면, 한 대의 부 서버만 있는 경우 해당 부 서버가 새로운 주 서버가 될것이며 모든 DB 연산은 새로운 주 서버상에서 실행된다. 
  운영 환경에서는 더 복잡한데, 부 서버에 보관된 데이터가 최신 상태가 아닐 수 있기 때문에 복구 스크립트를 돌려 추가해야된다. 
  다중 마스터나 원형 다중화 방식을 도입하면 이런 상황에 대처하는데 도움이 될 수도 있다.  

로드밸런서와 데이터베이스 다중화를 고려한 설계안은 다음과 같아진다. 
* 사용자는 DNS로부터 로드밸런서의 공개 IP주소를 받는다. 
* 사용자는 해당 IP주소를 사용해 로드밸런서에 접속한다. 
* HTTP 요청은 서버 1이나 서버2로 전달된다. 
* 웹 서버는 사용자의 데이터를 부 데이터베이스 서버에서 읽는다. 
* 웹 서버는 데이터 변경 연산은 주 데이터베이스로 전달한다. 데이터 추가, 삭제, 갱신 연산 등이 이에 해당한다. \

## 캐시
캐시는 값비싼 연산 결과 or 자주 참조되는 데이터를 메모리 안에 두고 뒤이은 요청이 보다 빨리 처리될 수 맀도록 하는 저장소다.  
애플리케이션의 성능은 DB를 멀마나 자주 호출하느냐에 크게 좌우되는데, 캐시는 그런 문제를 완화한다.

### 캐시 걔층
* 데이터가 잠시 보관되는 곳
* DB보다 빠르므로 성능이 개선됨
* DB의 부하를 줄일 수 있음
* 캐시 걔층의 규모를 독립적으로 확장할 수 있음  

**캐시 주도 전략**
1. 요청을 받은 웹 서버는 캐시에 응답이 저장되어 있는지 확인한다. 
   1. 저장되어 있으면 캐시에서 데이터를 읽는다.
   2. 그렇지 않다면 데이터베이스 질의를 통해 데이터를 찾아 캐시에 저장한다. 
2. 클라이언트에게 반환한다.

캐시를 사용 할 때는 아래 사항들을 고려해야한다.
* 캐시는 어떤 상황에 바람직한가? 
  * 데이터 갱신은 자주 일어나지 않지만 참조는 빈번하게 일어난다면 적합하겠다. 
* 어떤 데이터를 캐시에 두어야 할까? 
  * 캐시는 데이터를 휘발성 메모리에 두므로, 영속적으로 보관할 데이터를 캐시에 두는것은 바랍직하지 않다.
* 캐시에 보관된 데이터는 어떻게 만료되는가?
  * 만료기한은 너무 짧으면 DB를 너무 자주 읽게 될 것이고, 너무 길어도 원본과 차이가 날 가능성이 높이질 것이다. 
* 일관성은 어떻게 유지되는가? 
  * 데이터 저장소의 원본과 캐시 내의 사본이 같은가? 저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우 깨질 수 있다. 
* 장애는 어떻게 대처할 것인가? 
  * 캐시 서버를 한 대만 두는 경우 해당 서버는 단일 장애지점이 되어버릴 가능성이 있다. 
* 캐시 메모리는 얼마나 크게 잡을 것인가? 
  * 캐시 메모리가 너무 작으면 엑세스 패턴에 따라 데이터가 너무 자주 캐시에서 밀려나버려 캐시의 성능이 떨어지게된다. 
* 데이터 방출은 정책은 무엇인가? 
  * 캐시가 꽉 차버리면 추가로 캐시에 데이터를 넣아야 하는 경우 기존 데이터를 내보내야 한다. 가장 널리 쓰이는 것은 LRU이고 LFU, FIFO등이 있다.

## 콘텐츠 전송 네트워크 (CDN)
정적 콘텐츠를 전송하는데 쓰이는 지리적으로 분산된 서버의 네트워크이다. 이미지, 비디오, CSS, JavaScript파일 등을 캐시할 수 있다. 
사용자가 웹사이트 방문 시 사용자에게 가장 가까운 CDN 서버가 정적 콘텐츠를 전달하게 된다. 사용자가 CDN서버로 부터 멀면 멀수록 웹사이트는 천천히 로드된다.
1. 사용자 A가 이미지 URL을 이용에 image.png에 접근한다.
2. CDN 서버의 캐시에 해당 이미지가 없는 경우, 서버는 원본(origin) 서버에 요청해 파일을 가져온다.
3. 원본 서버가 파일을 CDN 서버에 반환한다. 응답의 HTTP 헤더에는 TTL 값이 들어있다. 
4. CDN 서버는 파일을 캐시하고 사용자 A에게 반환한다. 
5. 사용자 B가 같은 이미지에 대한 요청을 CDN서버에 전송한다. 
6. 만료되지 않은 이미지에 대한 요청은 캐시를 통해 처리된다. 

### CDN 사용시 고래해야할 사항
* 비용
* 적절한 만료시한 설정
* CDN 장애에 대한 대처 방안
* 콘텐츠 무효화 방법
  * CDN 서비스 사업자가 제공하는 API를 이용해 콘텐츠 무효화
  * 콘텐츠의 다른 버전을 서비스하도록 오브젝트 버저닝 이용. eg) URL 마지막에 버전 본호를 인자로 주는 방식 등

## 무상태(stateless) 웹 계층
웹 계층을 수평적으로 확장하는 방법을 생각해보자. 이를 위해 상태 정보를 웹 계층에서 제거해야 한다. 
상태정보를 RDB나 NoSQL같은 지속성 저장소에 보관하고 필요하면 가져오도록 하면 될 것이다.

### 상태 정보 의존적인 아키택쳐
상태 정보를 저장하는 아키택쳐의 문제는 같은 클라이언트로부터의 요청은 항상 같은 서버로 전송되어야 한다는 것이다. 사용자A의 정보가 서버1에 저장되 있다면, 해당 사용자의 요청은 무조건 서버1으로 가야한다.
요청이 서버2로 전송되면 이 서버에는 사용자 A의 정보가 없어 인증이 실패할 것이기 때문이다. 
로드밸런서가 이를 지원하기 위해 고정 세선(sticky session)이라는 기능을 지원하고 있으나, 이는 로드밸런서에게 부담을준다. 
게다가 로드밸런서 뒷단에 서버를 추가하거나 제거하기도 까다로워지고 서버의 장애를 처리하기도 복잡해진다.
### 무상태 아키택쳐
이 구조에서 사용자로부터의 요청은 어떤 웹 서버로도 전달될 수 있다. 공유 저장소에 모든 데이터가 저장되어있기 때문이다.
이러한 구조는 단순하고, 안정적이며 규모 확장이 쉽다.

## 데이터 센터
지리적 라우팅(geoDNS-routing 또는 geo-routing)은 장애가 없는 상황에서 사용자에게 가까운 데이터 센터로 안내하는 것을 말한다.
geoDNS는 사용자의 위치에 따라 도메인 이름을 어떤 IP주소로 변환할지 결정할 수 있도록 해주는 DNS 서비스이다. 
다중 데이터센터 아키택처를 만들려면 몇가지 기술적 난제를 해결해야 한다.
* 트래픽 우회: 올바른 데이터 센터로 트래픽을 보내는 효과적인 방법을 찾아야한다.
* 데이터 동기화: 데이터 센터마다 별도의 DB를 사용하고 있는 상황이라면 장애가 자동으로 복구되어 트래픽이 다른 DB로 우회된다고 해도 해당 데이터 센터를 찾는 데이터가 없을 수 있다. 
  이를 막는 일반적 전략은 데이터를 여러 데이터센터에 걸쳐 다중화하는 것이다.
* 테스트와 배포: 여러 데이터 센터를 사용하도록 시스템이 구성된 상황이라면 웹 사이트 또는 애플리케이션을 여러 위치에서 테스트해보아야한다.
 자동화된 배포 도구는 모든 데이터 센터에 동일한 서비스가 설치되도록 하는 데 중요한 역할을 한다.

## 메시지 큐
메시지 큐는 많은 분산 시스템이 더 큰 규모로 확정하기 위해 시스템의 컴포넌트를 분리하여 독립적으로 확정할 수 있도록 해준다. 
이는 메시지의 무손실을 보장하는, 비동기 통신을 지원하는 컴포넌트다.
메지지의 버퍼 역할을 하며 비동기적으로 전송한다.
* 생산자/발행자가 메시지를 만들어 메시지 큐에 발행한다.
* 큐에는 소비자/구독자가 연결되어 있어 메시지를 받아 그에 맞는 동작을 수행한다.  

메시지 큐를 이용하면 서비스 or 서버 간 결합이 느슨해져 규모 확장성이 보장되어야하는 안정적 어플리케이션을 구성하기 좋다. 

## 로그, 메트릭 그리고 자동화
* 로그: 시스템의 오류와 문제들을 보다 쉽게 찾아내기 위해 에러 모니터링은 중요하다.
* 메트릭: 잘 수집시 사업 현황에 관한 유용한 정보를 얻을 수 있고, 시스템의 현재 상태를 손쉽게 파악할 수 있다.
  * 호스트 단위 메트릭: CPU, 메모리, 디스크 I/O
  * 종합 메트릭: 데이터베이스 계층의 성능, 캐시 계층의 성능
  * 핵심 비즈니스 매트릭: 일별 능동 사용자, 수익, 재방문등
* 자동화: 시스템이 크고 복잡해지면서는 생산성을 높이기 위해 사용된다.

## 데이터베이스의 규모 확장
### 수직적 확장
기존 서버에 더 많은 또는 더 고성능(CPU, RAM, 디스크 등)의 자원을 증설하는 방법.  
아래와 같은 단점이 존재한다.
* DB 서버 하드웨어에는 한계가 있으므로 CPU, RAM 등을 무한 증설할 수는 없다. 사용하자 계속 늘어나면 한 대 서버로는 감당하기 어렵다.
* SPOF(Single Point of Failure)로 인한 위험성이 크다.
* 비용이 많이든다.

### 수평적 확장
샤딩이라고도 부르는데 더 많은 서버를 추가해 성능을 향상시킨다.  
샤딩은 대규모 데이터베이스를 샤드라고 부르는 작은 단위로 분할하는 기술을 일컫는다. 모든 샤드는 같은 스키마를 쓰지만 샤드에 보관되는 데이터 사이에는 중복이 없다.  
샤딩 전략을 구현할 때 샤딩 키를 어떻게 정하는지가 가장 중요하다. 이는 파티션 키라고도 부르는데, 데이터가 어떻게 분산될지 정하는 하나 이상의 칼럼으로 구성된다. 
샤딩 키를 정할 때는 데이터를 고르게 분할 할 수 있도록 하는 게 가장 중요하다.  
샤딩을 도입하면 다음과 같은 문제가 생긴다.
* 데이터의 재 샤딩:
  * 데이터가 너무 많아져서 하나의 샤드로는 감당하기 어려울 때
  * 샤드 간 데이터 분포가 균등하지 못하여 어떤 샤드에 할당된 공간 소모가 다른 샤드에 비해 빨리 진행될 때
* 유명인사 문제: 핫스팟 키 문제라고도 불림. 특정 샤드에 질의가 집중되어 서버에 과부하가 걸리는 문제
* 조인과 비정규화: 여러 샤드에 걸친 데이터를 조인하기 힘들어진다.

## 백만 사용자, 그리고 그 이상
시스템의 규모를 확장하는 것은 지속적이고 반복적인 과정이다. 위에서 다룬 내용을 반복하다 보면 원하는 규모의 시스템을 달성할 수 있을 것이다.
그럼에도 사용자가 늘어날 수록 새로운 전략을 도입하고 시스템을 지속적으로 가다듬어야 할 것이다.  
이번 장의 내용을 정리해 보자.
* 웹 계층은 무상태 계층으로
* 모든 계층에 다중화 도입
* 가능한 많은 데이터를 캐시할 것
* 여러 데이터 센터를 지원할 것
* 정적 콘텐츠는 CDN을 통해 서비스할 것
* 데이터 계층은 샤딩을 통해 그 규모를 확장할 것
* 각 계층은 독립적 서비스로 분할할 것
* 시스템을 지속적으로 모니터링하고, 자동화 도구들을 활용할 것
